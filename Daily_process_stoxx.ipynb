{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1b911b-0244-4b5d-b7c2-b361ca8d1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Historical Price Data with ADV Filter using LSEG Data Packages\n",
    "\n",
    "This script fetches historical price and volume data, then filters stocks\n",
    "based on 3-month Average Daily Volume (ADV) >= 5M USD.\n",
    "\n",
    "ADV formula: ADV_t = (1/60) * Σ(USD_Volume_{t-i}) for i=1 to 60\n",
    "\"\"\"\n",
    "\n",
    "import lseg.data as ld\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea616b55-f5ed-43f2-8f6e-3283c38a5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /home/jovyan/Daily_new_data_stoxx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"/home/jovyan/Daily_new_data_stoxx\")\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Saving to:\", BASE_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a283c77-835e-4698-b2f1-e02c37fa1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lseg.data.session.Definition object at 0x7f801ccab040 {name='codebook'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.open_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8026e69-2ace-4097-a470-dd3d0571e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Company Common Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSE.L</td>\n",
       "      <td>SSE PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAK.ST</td>\n",
       "      <td>AAK AB (publ)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDR.L</td>\n",
       "      <td>Schroders PLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SASY.PA</td>\n",
       "      <td>Sanofi SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NSISb.CO</td>\n",
       "      <td>Novozymes A/S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Instrument Company Common Name\n",
       "0      SSE.L             SSE PLC\n",
       "1     AAK.ST       AAK AB (publ)\n",
       "2      SDR.L       Schroders PLC\n",
       "3    SASY.PA           Sanofi SA\n",
       "4   NSISb.CO       Novozymes A/S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoxx = ld.get_data(\"0#.STOXX\",fields = 'TR.CommonName')\n",
    "stoxx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb4b808-a5ae-4273-a490-12ebfbb236b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rics = stoxx[\"Instrument\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c653c4e-b6e5-4f6b-a538-916c1f321558",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = '2026-02-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545cae97-cdd5-4604-954c-b63f111c1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(rics, start_date, end_date, fields=None, batch_size=50):\n",
    "    \"\"\"\n",
    "    Fetch historical price and volume data in batches (single-core)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rics : list\n",
    "        List of Reuters Instrument Codes (RICs)\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    fields : list, optional\n",
    "        Fields to retrieve. Default includes price and volume fields.\n",
    "    batch_size : int, optional\n",
    "        Number of RICs to process per batch (default: 50)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Historical data with multi-index (Date, RIC)\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = [\n",
    "            'TR.PriceClose',           # Closing price\n",
    "            #'TR.PriceOpen',            # Opening price\n",
    "            #'TR.PriceHigh',            # High price\n",
    "            #'TR.PriceLow',             # Low price\n",
    "            'TR.Volume',               # Trading volume (shares)\n",
    "            'TR.PriceClose.currency',   # Currency for price\n",
    "            'TR.TotalReturn1D',\n",
    "            #'TR.TRBCEconomicSector' # static object process later\n",
    "            \n",
    "        ]\n",
    "    \n",
    "    total_rics = len(rics)\n",
    "    num_batches = (total_rics + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nFetching data for {total_rics} instruments...\")\n",
    "    print(f\"Date range: {end_date}\")\n",
    "    print(f\"Processing in {num_batches} batches of ~{batch_size} RICs each (single-core)\\n\")\n",
    "    \n",
    "    all_data = []\n",
    "    failed_batches = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for batch_num in range(num_batches):\n",
    "            # Get batch of RICs\n",
    "            batch_start = batch_num * batch_size\n",
    "            batch_end = min((batch_num + 1) * batch_size, total_rics)\n",
    "            batch_rics = rics[batch_start:batch_end]\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Fetch batch data\n",
    "                df_batch = ld.get_history(\n",
    "                    universe=batch_rics,\n",
    "                    fields=fields,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    interval='daily',\n",
    "                    #count = look_back_days,\n",
    "                    #parameters = {'Curn': 'USD'}\n",
    "                )\n",
    "                \n",
    "                if not df_batch.empty:\n",
    "                    df_batch = df_batch.stack(level=0)   # stack RICs\n",
    "                    all_data.append(df_batch)\n",
    "                    print(\"✓\")\n",
    "                else:\n",
    "                    print(\"✗ (no data)\")\n",
    "                \n",
    "\n",
    "\n",
    "                progress = (batch_end / total_rics) * 100\n",
    "                print(f\"Progress: {progress:5.1f}% | Batch {batch_num+1}/{num_batches}s\")\n",
    "                        \n",
    "            except Exception as batch_error:\n",
    "                failed_batches.append(batch_num + 1)\n",
    "                print(f\"\\n⚠ Warning: Batch {batch_num+1} failed: {batch_error}\")\n",
    "\n",
    "        \n",
    "        # Combine all batches\n",
    "        if all_data:\n",
    "            df_combined = pd.concat(all_data)\n",
    "            df_combined.index.names = [\"Date\", \"RIC\"]\n",
    "            \n",
    "            #print(f\"\\n✓ Retrieved {len(df_combined):,} data points in {elapsed:.1f}s\")\n",
    "            #print(f\"  Unique instruments: {df_combined['Instrument'].nunique()}\")\n",
    "            #print(f\"  Date range: {df_combined['Date'].min()} to {df_combined['Date'].max()}\")\n",
    "            \n",
    "            if failed_batches:\n",
    "                print(f\"  ⚠ Failed batches: {failed_batches}\")\n",
    "            \n",
    "            return df_combined\n",
    "        else:\n",
    "            print(f\"\\n✗ No data retrieved\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error fetching historical data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "036f66de-5faf-4df5-ad9a-a77f1602df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 600 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 12 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   8.3% | Batch 1/12s\n",
      "✓\n",
      "Progress:  16.7% | Batch 2/12s\n",
      "✓\n",
      "Progress:  25.0% | Batch 3/12s\n",
      "✓\n",
      "Progress:  33.3% | Batch 4/12s\n",
      "✓\n",
      "Progress:  41.7% | Batch 5/12s\n",
      "✓\n",
      "Progress:  50.0% | Batch 6/12s\n",
      "✓\n",
      "Progress:  58.3% | Batch 7/12s\n",
      "✓\n",
      "Progress:  66.7% | Batch 8/12s\n",
      "✓\n",
      "Progress:  75.0% | Batch 9/12s\n",
      "✓\n",
      "Progress:  83.3% | Batch 10/12s\n",
      "✓\n",
      "Progress:  91.7% | Batch 11/12s\n",
      "✓\n",
      "Progress: 100.0% | Batch 12/12s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data(rics, start_date, end_date, fields = None)\n",
    "\n",
    "df_final = df.reset_index()\n",
    "df_final.to_csv(BASE_DIR /\"stoxx_historyprice_data_now_to_20260219.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c6dc2b-9f7d-49b8-8518-485a37704790",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = df[\"Currency\"].unique().tolist()\n",
    "clean_fx = [c + \"=\" for c in curr if c != \"\"]\n",
    "\n",
    "df_fx = ld.get_history(\n",
    "    universe=clean_fx,\n",
    "    fields=\"TR.MIDPRICE\",\n",
    "    interval=\"daily\",\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    ")\n",
    "\n",
    "df_final = df_fx.reset_index()\n",
    "\n",
    "df_final.to_csv(BASE_DIR /\"currency_data_now_to_20260219.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e6aa09-3643-473d-bf0c-3d30035e259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data_pe(rics, start_date, end_date, fields=None, batch_size=50):\n",
    "    \"\"\"\n",
    "    Fetch historical price and volume data in batches (single-core)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rics : list\n",
    "        List of Reuters Instrument Codes (RICs)\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    fields : list, optional\n",
    "        Fields to retrieve. Default includes price and volume fields.\n",
    "    batch_size : int, optional\n",
    "        Number of RICs to process per batch (default: 50)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Historical data with multi-index (Date, RIC)\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = [\n",
    "            #'TR.PriceClose',           # Closing price\n",
    "            #'TR.PriceOpen',            # Opening price\n",
    "            #'TR.PriceHigh',            # High price\n",
    "            #'TR.PriceLow',             # Low price\n",
    "            #'TR.Volume',               # Trading volume (shares)\n",
    "            'TR.PriceClose.currency',   # Currency for price\n",
    "            #'TR.TotalReturn1D',\n",
    "            #'TR.TRBCEconomicSector' # static object process later\n",
    "            \"TR.PE\",\n",
    "            \n",
    "        ]\n",
    "    \n",
    "    total_rics = len(rics)\n",
    "    num_batches = (total_rics + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nFetching data for {total_rics} instruments...\")\n",
    "    print(f\"Date range: {end_date}\")\n",
    "    print(f\"Processing in {num_batches} batches of ~{batch_size} RICs each (single-core)\\n\")\n",
    "    \n",
    "    all_data = []\n",
    "    failed_batches = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for batch_num in range(num_batches):\n",
    "            # Get batch of RICs\n",
    "            batch_start = batch_num * batch_size\n",
    "            batch_end = min((batch_num + 1) * batch_size, total_rics)\n",
    "            batch_rics = rics[batch_start:batch_end]\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Fetch batch data\n",
    "                df_batch = ld.get_history(\n",
    "                    universe=batch_rics,\n",
    "                    fields=fields,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    interval='daily',\n",
    "                    #count = look_back_days,\n",
    "                    #parameters = {'Curn': 'USD'}\n",
    "                )\n",
    "                \n",
    "                if not df_batch.empty:\n",
    "                    df_batch = df_batch.stack(level=0)   # stack RICs\n",
    "                    all_data.append(df_batch)\n",
    "                    print(\"✓\")\n",
    "                else:\n",
    "                    print(\"✗ (no data)\")\n",
    "                \n",
    "\n",
    "\n",
    "                progress = (batch_end / total_rics) * 100\n",
    "                print(f\"Progress: {progress:5.1f}% | Batch {batch_num+1}/{num_batches}s\")\n",
    "                        \n",
    "            except Exception as batch_error:\n",
    "                failed_batches.append(batch_num + 1)\n",
    "                print(f\"\\n⚠ Warning: Batch {batch_num+1} failed: {batch_error}\")\n",
    "\n",
    "        \n",
    "        # Combine all batches\n",
    "        if all_data:\n",
    "            df_combined = pd.concat(all_data)\n",
    "            df_combined.index.names = [\"Date\", \"RIC\"]\n",
    "            \n",
    "            # Rename column to a clean title\n",
    "            #df_combined.columns = [\"Price to Earning\"]\n",
    "            \n",
    "            #print(f\"\\n✓ Retrieved {len(df_combined):,} data points in {elapsed:.1f}s\")\n",
    "            #print(f\"  Unique instruments: {df_combined['Instrument'].nunique()}\")\n",
    "            #print(f\"  Date range: {df_combined['Date'].min()} to {df_combined['Date'].max()}\")\n",
    "            \n",
    "            if failed_batches:\n",
    "                print(f\"  ⚠ Failed batches: {failed_batches}\")\n",
    "            \n",
    "            return df_combined\n",
    "        else:\n",
    "            print(f\"\\n✗ No data retrieved\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error fetching historical data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dbc50-8526-4d7f-ae4c-e70ee6b93355",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE_fields = ['TR.PriceClose.currency',\"TR.PE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed7c285-b73a-43da-af10-aef8d372cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 600 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 12 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   8.3% | Batch 1/12s\n",
      "✓\n",
      "Progress:  16.7% | Batch 2/12s\n",
      "✓\n",
      "Progress:  25.0% | Batch 3/12s\n",
      "✓\n",
      "Progress:  33.3% | Batch 4/12s\n",
      "✓\n",
      "Progress:  41.7% | Batch 5/12s\n",
      "✓\n",
      "Progress:  50.0% | Batch 6/12s\n",
      "✓\n",
      "Progress:  58.3% | Batch 7/12s\n",
      "✓\n",
      "Progress:  66.7% | Batch 8/12s\n",
      "✓\n",
      "Progress:  75.0% | Batch 9/12s\n",
      "✓\n",
      "Progress:  83.3% | Batch 10/12s\n",
      "✓\n",
      "Progress:  91.7% | Batch 11/12s\n",
      "✓\n",
      "Progress: 100.0% | Batch 12/12s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data_pe(rics, start_date, end_date, fields = PE_fields)\n",
    "\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"P/E (Daily Time Series Ratio)\": \"Price to Earning\"\n",
    "})\n",
    "\n",
    "    \n",
    "df_final = df.reset_index()\n",
    "\n",
    "\n",
    "df_final.to_csv(BASE_DIR /\"stoxx_Price-Earning_data_now_to_20260219.csv\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396c2cf6-fd5e-436b-b7eb-de4145a66b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_historical_data(\".STOXX50E\", start_date, end_date, fields = None)\n",
    "\n",
    "df = ld.get_history(\n",
    "    universe=\".STOXX50E\",\n",
    "    fields=\"TR.PriceClose\",\n",
    "    interval=\"daily\",\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    ")\n",
    "\n",
    "if isinstance(df, pd.Series):\n",
    "    df = df.to_frame(name=\"Close Price\")\n",
    "    \n",
    "df_final.to_csv(BASE_DIR /\"stoxx_historyprice_Eurostoxx50_now_to_20260219.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b56b2-0667-4f25-a8e1-3042d05facbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_usd_volume(df):\n",
    "    \"\"\"\n",
    "    Calculate USD trading volume for each (Date, RIC)\n",
    "\n",
    "    USD_Volume = Volume * Price Close * FX_Rate (if not USD)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain:\n",
    "        ['Volume', 'Price Close', 'Currency']\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        With added 'USD_Volume' column\n",
    "    \"\"\"\n",
    "    print(\"\\nCalculating USD volume...\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Sanity check\n",
    "    required_cols = {\"Volume\", \"Price Close\", \"Currency\"}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Base calculation (assume USD)\n",
    "    df[\"USD_Volume\"] = df[\"Volume\"] * df[\"Price Close\"]\n",
    "\n",
    "    # Identify non-USD rows\n",
    "    non_usd = df[\"Currency\"] != \"USD\"\n",
    "    non_usd_df = df.loc[df[\"Currency\"].ne(\"USD\")].copy()\n",
    "\n",
    "\n",
    "    if non_usd.any():\n",
    "        print(f\"⚠ {non_usd.sum()} rows are non-USD (FX rate = 1.0 placeholder)\")\n",
    "        # Placeholder FX rate\n",
    "        df.loc[non_usd, \"USD_Volume\"] *= 1.0\n",
    "\n",
    "    return df, non_usd_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1a61b-9074-4085-8726-a859e5c48500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adv(df, lookback_days=75, min_coverage=0.8):\n",
    "    print(f\"\\nCalculating {lookback_days}-day ADV for each stock...\")\n",
    "\n",
    "    adv_records = []\n",
    "\n",
    "    for ric, g in df.groupby(level=\"RIC\"):\n",
    "        g = g.sort_index(level=\"Date\")\n",
    "\n",
    "        recent = g.tail(lookback_days)\n",
    "        n_obs = recent[\"USD_Volume\"].notna().sum()\n",
    "\n",
    "        if n_obs >= lookback_days * min_coverage:\n",
    "            adv_records.append({\n",
    "                \"RIC\": ric,\n",
    "                \"ADV_USD\": recent[\"USD_Volume\"].mean(),\n",
    "                \"Days_Used\": n_obs,\n",
    "                \"Latest_Date\": recent.index.get_level_values(\"Date\")[-1]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  Warning: Insufficient data for {ric} ({n_obs} days)\")\n",
    "\n",
    "    return pd.DataFrame(adv_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c9ab5-7632-47a7-8ceb-db4d041a3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_single_stock_limits(\n",
    "    adv_summary: pd.DataFrame,\n",
    "    threshold_usd: float = 5_000_000,\n",
    "    adv_col: str = \"ADV_USD\",\n",
    "    ric_col: str = \"RIC\",\n",
    "    pct_of_adv: float = 0.025,\n",
    "    max_usd_cap: float = 2_000_000,\n",
    "    limit_col: str = \"Daily_Limit_USD\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Step 1: Screen by ADV >= threshold_usd (e.g. 5M).\n",
    "    Step 2: For kept names, compute Daily_Limit_USD = min(pct_of_adv * ADV, max_usd_cap).\n",
    "\n",
    "    Returns:\n",
    "        filtered_adv: kept rows with Daily_Limit_USD added\n",
    "        excluded_adv: excluded rows (no daily limit computed)\n",
    "        kept_rics: list of kept RICs\n",
    "    \"\"\"\n",
    "    df = adv_summary.copy()\n",
    "\n",
    "    required = {adv_col, ric_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    df[adv_col] = pd.to_numeric(df[adv_col], errors=\"coerce\")\n",
    "\n",
    "    # Step 1: ADV screen\n",
    "    mask_keep = df[adv_col] >= threshold_usd\n",
    "    filtered_adv = df.loc[mask_keep].copy()\n",
    "    excluded_adv = df.loc[~mask_keep].copy()\n",
    "    kept_rics = filtered_adv[ric_col].dropna().tolist()\n",
    "\n",
    "    # Step 2: compute daily trading limit only for kept\n",
    "    filtered_adv[limit_col] = (filtered_adv[adv_col] * pct_of_adv).clip(upper=max_usd_cap)\n",
    "\n",
    "\n",
    "    return filtered_adv, excluded_adv, kept_rics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30622e82-91dc-406f-951b-5adaa9d8a542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
