{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1b911b-0244-4b5d-b7c2-b361ca8d1bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Historical Price Data with ADV Filter using LSEG Data Packages\n",
    "\n",
    "This script fetches historical price and volume data, then filters stocks\n",
    "based on 3-month Average Daily Volume (ADV) >= 5M USD.\n",
    "\n",
    "ADV formula: ADV_t = (1/60) * Σ(USD_Volume_{t-i}) for i=1 to 60\n",
    "\"\"\"\n",
    "\n",
    "import lseg.data as ld\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a246a3a-5d9d-4024-addf-857e35d06b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: /home/jovyan/Daily_new_data_russel\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"/home/jovyan/Daily_new_data_russel\")\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Saving to:\", BASE_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a283c77-835e-4698-b2f1-e02c37fa1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lseg.data.session.Definition object at 0x7f4eff535040 {name='codebook'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld.open_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8026e69-2ace-4097-a470-dd3d0571e4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Company Common Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIGL.OQ</td>\n",
       "      <td>Rigel Pharmaceuticals Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NIC.N</td>\n",
       "      <td>Nicolet Bankshares Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EHAB.N</td>\n",
       "      <td>Enhabit Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNP.N</td>\n",
       "      <td>Union Pacific Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AON.N</td>\n",
       "      <td>Aon PLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Instrument        Company Common Name\n",
       "0    RIGL.OQ  Rigel Pharmaceuticals Inc\n",
       "1      NIC.N     Nicolet Bankshares Inc\n",
       "2     EHAB.N                Enhabit Inc\n",
       "3      UNP.N         Union Pacific Corp\n",
       "4      AON.N                    Aon PLC"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "russel = ld.get_data(\"0#.RUA\",fields = 'TR.CommonName')\n",
    "russel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb4b808-a5ae-4273-a490-12ebfbb236b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rics = russel[\"Instrument\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c653c4e-b6e5-4f6b-a538-916c1f321558",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "start_date = '2026-02-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545cae97-cdd5-4604-954c-b63f111c1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(rics, start_date, end_date, fields=None, batch_size=50):\n",
    "    \"\"\"\n",
    "    Fetch historical price and volume data in batches (single-core)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rics : list\n",
    "        List of Reuters Instrument Codes (RICs)\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    fields : list, optional\n",
    "        Fields to retrieve. Default includes price and volume fields.\n",
    "    batch_size : int, optional\n",
    "        Number of RICs to process per batch (default: 50)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Historical data with multi-index (Date, RIC)\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = [\n",
    "            'TR.PriceClose',           # Closing price\n",
    "            #'TR.PriceOpen',            # Opening price\n",
    "            #'TR.PriceHigh',            # High price\n",
    "            #'TR.PriceLow',             # Low price\n",
    "            'TR.Volume',               # Trading volume (shares)\n",
    "            'TR.PriceClose.currency',   # Currency for price\n",
    "            'TR.TotalReturn1D',\n",
    "            #'TR.TRBCEconomicSector' # static object process later\n",
    "            \n",
    "        ]\n",
    "    \n",
    "    total_rics = len(rics)\n",
    "    num_batches = (total_rics + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nFetching data for {total_rics} instruments...\")\n",
    "    print(f\"Date range: {end_date}\")\n",
    "    print(f\"Processing in {num_batches} batches of ~{batch_size} RICs each (single-core)\\n\")\n",
    "    \n",
    "    all_data = []\n",
    "    failed_batches = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for batch_num in range(num_batches):\n",
    "            # Get batch of RICs\n",
    "            batch_start = batch_num * batch_size\n",
    "            batch_end = min((batch_num + 1) * batch_size, total_rics)\n",
    "            batch_rics = rics[batch_start:batch_end]\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Fetch batch data\n",
    "                df_batch = ld.get_history(\n",
    "                    universe=batch_rics,\n",
    "                    fields=fields,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    interval='daily',\n",
    "                    #count = look_back_days,\n",
    "                    parameters = {'Curn': 'USD'}\n",
    "                )\n",
    "                \n",
    "                if not df_batch.empty:\n",
    "                    df_batch = df_batch.stack(level=0)   # stack RICs\n",
    "                    all_data.append(df_batch)\n",
    "                    print(\"✓\")\n",
    "                else:\n",
    "                    print(\"✗ (no data)\")\n",
    "                \n",
    "\n",
    "\n",
    "                progress = (batch_end / total_rics) * 100\n",
    "                print(f\"Progress: {progress:5.1f}% | Batch {batch_num+1}/{num_batches}s\")\n",
    "                        \n",
    "            except Exception as batch_error:\n",
    "                failed_batches.append(batch_num + 1)\n",
    "                print(f\"\\n⚠ Warning: Batch {batch_num+1} failed: {batch_error}\")\n",
    "\n",
    "        \n",
    "        # Combine all batches\n",
    "        if all_data:\n",
    "            df_combined = pd.concat(all_data)\n",
    "            df_combined.index.names = [\"Date\", \"RIC\"]\n",
    "            \n",
    "            #print(f\"\\n✓ Retrieved {len(df_combined):,} data points in {elapsed:.1f}s\")\n",
    "            #print(f\"  Unique instruments: {df_combined['Instrument'].nunique()}\")\n",
    "            #print(f\"  Date range: {df_combined['Date'].min()} to {df_combined['Date'].max()}\")\n",
    "            \n",
    "            if failed_batches:\n",
    "                print(f\"  ⚠ Failed batches: {failed_batches}\")\n",
    "            \n",
    "            return df_combined\n",
    "        else:\n",
    "            print(f\"\\n✗ No data retrieved\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error fetching historical data: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781e1348-af17-451b-b3a8-667877c1d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"rics_20260214_ADVfiltered.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kept_rics = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036f66de-5faf-4df5-ad9a-a77f1602df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 2938 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 59 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   1.7% | Batch 1/59s\n",
      "✓\n",
      "Progress:   3.4% | Batch 2/59s\n",
      "✓\n",
      "Progress:   5.1% | Batch 3/59s\n",
      "✓\n",
      "Progress:   6.8% | Batch 4/59s\n",
      "✓\n",
      "Progress:   8.5% | Batch 5/59s\n",
      "✓\n",
      "Progress:  10.2% | Batch 6/59s\n",
      "✓\n",
      "Progress:  11.9% | Batch 7/59s\n",
      "✓\n",
      "Progress:  13.6% | Batch 8/59s\n",
      "✓\n",
      "Progress:  15.3% | Batch 9/59s\n",
      "✓\n",
      "Progress:  17.0% | Batch 10/59s\n",
      "✓\n",
      "Progress:  18.7% | Batch 11/59s\n",
      "✓\n",
      "Progress:  20.4% | Batch 12/59s\n",
      "✓\n",
      "Progress:  22.1% | Batch 13/59s\n",
      "✓\n",
      "Progress:  23.8% | Batch 14/59s\n",
      "✓\n",
      "Progress:  25.5% | Batch 15/59s\n",
      "✓\n",
      "Progress:  27.2% | Batch 16/59s\n",
      "✓\n",
      "Progress:  28.9% | Batch 17/59s\n",
      "✓\n",
      "Progress:  30.6% | Batch 18/59s\n",
      "✓\n",
      "Progress:  32.3% | Batch 19/59s\n",
      "✓\n",
      "Progress:  34.0% | Batch 20/59s\n",
      "✓\n",
      "Progress:  35.7% | Batch 21/59s\n",
      "✓\n",
      "Progress:  37.4% | Batch 22/59s\n",
      "✓\n",
      "Progress:  39.1% | Batch 23/59s\n",
      "✓\n",
      "Progress:  40.8% | Batch 24/59s\n",
      "✓\n",
      "Progress:  42.5% | Batch 25/59s\n",
      "✓\n",
      "Progress:  44.2% | Batch 26/59s\n",
      "✓\n",
      "Progress:  45.9% | Batch 27/59s\n",
      "✓\n",
      "Progress:  47.7% | Batch 28/59s\n",
      "✓\n",
      "Progress:  49.4% | Batch 29/59s\n",
      "✓\n",
      "Progress:  51.1% | Batch 30/59s\n",
      "✓\n",
      "Progress:  52.8% | Batch 31/59s\n",
      "✓\n",
      "Progress:  54.5% | Batch 32/59s\n",
      "✓\n",
      "Progress:  56.2% | Batch 33/59s\n",
      "✓\n",
      "Progress:  57.9% | Batch 34/59s\n",
      "✓\n",
      "Progress:  59.6% | Batch 35/59s\n",
      "✓\n",
      "Progress:  61.3% | Batch 36/59s\n",
      "✓\n",
      "Progress:  63.0% | Batch 37/59s\n",
      "✓\n",
      "Progress:  64.7% | Batch 38/59s\n",
      "✓\n",
      "Progress:  66.4% | Batch 39/59s\n",
      "✓\n",
      "Progress:  68.1% | Batch 40/59s\n",
      "✓\n",
      "Progress:  69.8% | Batch 41/59s\n",
      "✓\n",
      "Progress:  71.5% | Batch 42/59s\n",
      "✓\n",
      "Progress:  73.2% | Batch 43/59s\n",
      "✓\n",
      "Progress:  74.9% | Batch 44/59s\n",
      "✓\n",
      "Progress:  76.6% | Batch 45/59s\n",
      "✓\n",
      "Progress:  78.3% | Batch 46/59s\n",
      "✓\n",
      "Progress:  80.0% | Batch 47/59s\n",
      "✓\n",
      "Progress:  81.7% | Batch 48/59s\n",
      "✓\n",
      "Progress:  83.4% | Batch 49/59s\n",
      "✓\n",
      "Progress:  85.1% | Batch 50/59s\n",
      "✓\n",
      "Progress:  86.8% | Batch 51/59s\n",
      "✓\n",
      "Progress:  88.5% | Batch 52/59s\n",
      "✓\n",
      "Progress:  90.2% | Batch 53/59s\n",
      "✓\n",
      "Progress:  91.9% | Batch 54/59s\n",
      "✓\n",
      "Progress:  93.6% | Batch 55/59s\n",
      "✓\n",
      "Progress:  95.3% | Batch 56/59s\n",
      "✓\n",
      "Progress:  97.0% | Batch 57/59s\n",
      "✓\n",
      "Progress:  98.7% | Batch 58/59s\n",
      "✓\n",
      "Progress: 100.0% | Batch 59/59s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data(rics, start_date, end_date, fields = None)\n",
    "\n",
    "df_final = df.reset_index()\n",
    "df_final.to_csv(BASE_DIR /\"lseg_historyprice_data_now_to_20260212.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b42f95f6-bfdb-46d1-b914-102623ace95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 1849 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 37 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   2.7% | Batch 1/37s\n",
      "✓\n",
      "Progress:   5.4% | Batch 2/37s\n",
      "✓\n",
      "Progress:   8.1% | Batch 3/37s\n",
      "✓\n",
      "Progress:  10.8% | Batch 4/37s\n",
      "✓\n",
      "Progress:  13.5% | Batch 5/37s\n",
      "✓\n",
      "Progress:  16.2% | Batch 6/37s\n",
      "✓\n",
      "Progress:  18.9% | Batch 7/37s\n",
      "✓\n",
      "Progress:  21.6% | Batch 8/37s\n",
      "✓\n",
      "Progress:  24.3% | Batch 9/37s\n",
      "✓\n",
      "Progress:  27.0% | Batch 10/37s\n",
      "✓\n",
      "Progress:  29.7% | Batch 11/37s\n",
      "✓\n",
      "Progress:  32.4% | Batch 12/37s\n",
      "✓\n",
      "Progress:  35.2% | Batch 13/37s\n",
      "✓\n",
      "Progress:  37.9% | Batch 14/37s\n",
      "✓\n",
      "Progress:  40.6% | Batch 15/37s\n",
      "✓\n",
      "Progress:  43.3% | Batch 16/37s\n",
      "✓\n",
      "Progress:  46.0% | Batch 17/37s\n",
      "✓\n",
      "Progress:  48.7% | Batch 18/37s\n",
      "✓\n",
      "Progress:  51.4% | Batch 19/37s\n",
      "✓\n",
      "Progress:  54.1% | Batch 20/37s\n",
      "✓\n",
      "Progress:  56.8% | Batch 21/37s\n",
      "✓\n",
      "Progress:  59.5% | Batch 22/37s\n",
      "✓\n",
      "Progress:  62.2% | Batch 23/37s\n",
      "✓\n",
      "Progress:  64.9% | Batch 24/37s\n",
      "✓\n",
      "Progress:  67.6% | Batch 25/37s\n",
      "✓\n",
      "Progress:  70.3% | Batch 26/37s\n",
      "✓\n",
      "Progress:  73.0% | Batch 27/37s\n",
      "✓\n",
      "Progress:  75.7% | Batch 28/37s\n",
      "✓\n",
      "Progress:  78.4% | Batch 29/37s\n",
      "✓\n",
      "Progress:  81.1% | Batch 30/37s\n",
      "✓\n",
      "Progress:  83.8% | Batch 31/37s\n",
      "✓\n",
      "Progress:  86.5% | Batch 32/37s\n",
      "✓\n",
      "Progress:  89.2% | Batch 33/37s\n",
      "✓\n",
      "Progress:  91.9% | Batch 34/37s\n",
      "✓\n",
      "Progress:  94.6% | Batch 35/37s\n",
      "✓\n",
      "Progress:  97.3% | Batch 36/37s\n",
      "✓\n",
      "Progress: 100.0% | Batch 37/37s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data(kept_rics, start_date, end_date, fields = None)\n",
    "\n",
    "df_final = df.reset_index()\n",
    "df_final.to_csv(BASE_DIR /\"lseg_historyprice_data_now_to_20260212_ADVfiltered.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e6aa09-3643-473d-bf0c-3d30035e259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data_pe(rics, start_date, end_date, fields=None, batch_size=50):\n",
    "    \"\"\"\n",
    "    Fetch historical price and volume data in batches (single-core)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rics : list\n",
    "        List of Reuters Instrument Codes (RICs)\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    fields : list, optional\n",
    "        Fields to retrieve. Default includes price and volume fields.\n",
    "    batch_size : int, optional\n",
    "        Number of RICs to process per batch (default: 50)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Historical data with multi-index (Date, RIC)\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = [\n",
    "            #'TR.PriceClose',           # Closing price\n",
    "            #'TR.PriceOpen',            # Opening price\n",
    "            #'TR.PriceHigh',            # High price\n",
    "            #'TR.PriceLow',             # Low price\n",
    "            #'TR.Volume',               # Trading volume (shares)\n",
    "            #'TR.PriceClose.currency',   # Currency for price\n",
    "            #'TR.TotalReturn1D',\n",
    "            #'TR.TRBCEconomicSector' # static object process later\n",
    "            \"TR.PE\",\n",
    "            \n",
    "        ]\n",
    "    \n",
    "    total_rics = len(rics)\n",
    "    num_batches = (total_rics + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"\\nFetching data for {total_rics} instruments...\")\n",
    "    print(f\"Date range: {end_date}\")\n",
    "    print(f\"Processing in {num_batches} batches of ~{batch_size} RICs each (single-core)\\n\")\n",
    "    \n",
    "    all_data = []\n",
    "    failed_batches = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for batch_num in range(num_batches):\n",
    "            # Get batch of RICs\n",
    "            batch_start = batch_num * batch_size\n",
    "            batch_end = min((batch_num + 1) * batch_size, total_rics)\n",
    "            batch_rics = rics[batch_start:batch_end]\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Fetch batch data\n",
    "                df_batch = ld.get_history(\n",
    "                    universe=batch_rics,\n",
    "                    fields=fields,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    interval='daily',\n",
    "                    #count = look_back_days,\n",
    "                    parameters = {'Curn': 'USD'}\n",
    "                )\n",
    "                \n",
    "                if not df_batch.empty:\n",
    "                    df_batch = df_batch.stack(level=0)   # stack RICs\n",
    "                    all_data.append(df_batch)\n",
    "                    print(\"✓\")\n",
    "                else:\n",
    "                    print(\"✗ (no data)\")\n",
    "                \n",
    "\n",
    "\n",
    "                progress = (batch_end / total_rics) * 100\n",
    "                print(f\"Progress: {progress:5.1f}% | Batch {batch_num+1}/{num_batches}s\")\n",
    "                        \n",
    "            except Exception as batch_error:\n",
    "                failed_batches.append(batch_num + 1)\n",
    "                print(f\"\\n⚠ Warning: Batch {batch_num+1} failed: {batch_error}\")\n",
    "\n",
    "        \n",
    "        # Combine all batches\n",
    "        if all_data:\n",
    "            df_combined = pd.concat(all_data)\n",
    "            df_combined.index.names = [\"Date\", \"RIC\"]\n",
    "            \n",
    "            # Rename column to a clean title\n",
    "            #df_combined.columns = [\"Price to Earning\"]\n",
    "            \n",
    "            #print(f\"\\n✓ Retrieved {len(df_combined):,} data points in {elapsed:.1f}s\")\n",
    "            #print(f\"  Unique instruments: {df_combined['Instrument'].nunique()}\")\n",
    "            #print(f\"  Date range: {df_combined['Date'].min()} to {df_combined['Date'].max()}\")\n",
    "            \n",
    "            if failed_batches:\n",
    "                print(f\"  ⚠ Failed batches: {failed_batches}\")\n",
    "            \n",
    "            return df_combined\n",
    "        else:\n",
    "            print(f\"\\n✗ No data retrieved\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error fetching historical data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed7c285-b73a-43da-af10-aef8d372cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 2938 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 59 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   1.7% | Batch 1/59s\n",
      "✓\n",
      "Progress:   3.4% | Batch 2/59s\n",
      "✓\n",
      "Progress:   5.1% | Batch 3/59s\n",
      "✓\n",
      "Progress:   6.8% | Batch 4/59s\n",
      "✓\n",
      "Progress:   8.5% | Batch 5/59s\n",
      "✓\n",
      "Progress:  10.2% | Batch 6/59s\n",
      "✓\n",
      "Progress:  11.9% | Batch 7/59s\n",
      "✓\n",
      "Progress:  13.6% | Batch 8/59s\n",
      "✓\n",
      "Progress:  15.3% | Batch 9/59s\n",
      "✓\n",
      "Progress:  17.0% | Batch 10/59s\n",
      "✓\n",
      "Progress:  18.7% | Batch 11/59s\n",
      "✓\n",
      "Progress:  20.4% | Batch 12/59s\n",
      "✓\n",
      "Progress:  22.1% | Batch 13/59s\n",
      "✓\n",
      "Progress:  23.8% | Batch 14/59s\n",
      "✓\n",
      "Progress:  25.5% | Batch 15/59s\n",
      "✓\n",
      "Progress:  27.2% | Batch 16/59s\n",
      "✓\n",
      "Progress:  28.9% | Batch 17/59s\n",
      "✓\n",
      "Progress:  30.6% | Batch 18/59s\n",
      "✓\n",
      "Progress:  32.3% | Batch 19/59s\n",
      "✓\n",
      "Progress:  34.0% | Batch 20/59s\n",
      "✓\n",
      "Progress:  35.7% | Batch 21/59s\n",
      "✓\n",
      "Progress:  37.4% | Batch 22/59s\n",
      "✓\n",
      "Progress:  39.1% | Batch 23/59s\n",
      "✓\n",
      "Progress:  40.8% | Batch 24/59s\n",
      "✓\n",
      "Progress:  42.5% | Batch 25/59s\n",
      "✓\n",
      "Progress:  44.2% | Batch 26/59s\n",
      "✓\n",
      "Progress:  45.9% | Batch 27/59s\n",
      "✓\n",
      "Progress:  47.7% | Batch 28/59s\n",
      "✓\n",
      "Progress:  49.4% | Batch 29/59s\n",
      "✓\n",
      "Progress:  51.1% | Batch 30/59s\n",
      "✓\n",
      "Progress:  52.8% | Batch 31/59s\n",
      "✓\n",
      "Progress:  54.5% | Batch 32/59s\n",
      "✓\n",
      "Progress:  56.2% | Batch 33/59s\n",
      "✓\n",
      "Progress:  57.9% | Batch 34/59s\n",
      "✓\n",
      "Progress:  59.6% | Batch 35/59s\n",
      "✓\n",
      "Progress:  61.3% | Batch 36/59s\n",
      "✓\n",
      "Progress:  63.0% | Batch 37/59s\n",
      "✓\n",
      "Progress:  64.7% | Batch 38/59s\n",
      "✓\n",
      "Progress:  66.4% | Batch 39/59s\n",
      "✓\n",
      "Progress:  68.1% | Batch 40/59s\n",
      "✓\n",
      "Progress:  69.8% | Batch 41/59s\n",
      "✓\n",
      "Progress:  71.5% | Batch 42/59s\n",
      "✓\n",
      "Progress:  73.2% | Batch 43/59s\n",
      "✓\n",
      "Progress:  74.9% | Batch 44/59s\n",
      "✓\n",
      "Progress:  76.6% | Batch 45/59s\n",
      "✓\n",
      "Progress:  78.3% | Batch 46/59s\n",
      "✓\n",
      "Progress:  80.0% | Batch 47/59s\n",
      "✓\n",
      "Progress:  81.7% | Batch 48/59s\n",
      "✓\n",
      "Progress:  83.4% | Batch 49/59s\n",
      "✓\n",
      "Progress:  85.1% | Batch 50/59s\n",
      "✓\n",
      "Progress:  86.8% | Batch 51/59s\n",
      "✓\n",
      "Progress:  88.5% | Batch 52/59s\n",
      "✓\n",
      "Progress:  90.2% | Batch 53/59s\n",
      "✓\n",
      "Progress:  91.9% | Batch 54/59s\n",
      "✓\n",
      "Progress:  93.6% | Batch 55/59s\n",
      "✓\n",
      "Progress:  95.3% | Batch 56/59s\n",
      "✓\n",
      "Progress:  97.0% | Batch 57/59s\n",
      "✓\n",
      "Progress:  98.7% | Batch 58/59s\n",
      "✓\n",
      "Progress: 100.0% | Batch 59/59s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data(rics, start_date, end_date, fields = \"TR.PE\")\n",
    "\n",
    "\n",
    "if isinstance(df, pd.Series):\n",
    "    df = df.to_frame(name=\"Price to Earning\")\n",
    "\n",
    "    \n",
    "df_final = df.reset_index()\n",
    "\n",
    "\n",
    "df_final.to_csv(BASE_DIR /\"lseg_Price-Earning_data_now_to_20260212.csv\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edde814f-9f95-49f0-a938-c6180ece6e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for 1849 instruments...\n",
      "Date range: 2026-02-21\n",
      "Processing in 37 batches of ~50 RICs each (single-core)\n",
      "\n",
      "✓\n",
      "Progress:   2.7% | Batch 1/37s\n",
      "✓\n",
      "Progress:   5.4% | Batch 2/37s\n",
      "✓\n",
      "Progress:   8.1% | Batch 3/37s\n",
      "✓\n",
      "Progress:  10.8% | Batch 4/37s\n",
      "✓\n",
      "Progress:  13.5% | Batch 5/37s\n",
      "✓\n",
      "Progress:  16.2% | Batch 6/37s\n",
      "✓\n",
      "Progress:  18.9% | Batch 7/37s\n",
      "✓\n",
      "Progress:  21.6% | Batch 8/37s\n",
      "✓\n",
      "Progress:  24.3% | Batch 9/37s\n",
      "✓\n",
      "Progress:  27.0% | Batch 10/37s\n",
      "✓\n",
      "Progress:  29.7% | Batch 11/37s\n",
      "✓\n",
      "Progress:  32.4% | Batch 12/37s\n",
      "✓\n",
      "Progress:  35.2% | Batch 13/37s\n",
      "✓\n",
      "Progress:  37.9% | Batch 14/37s\n",
      "✓\n",
      "Progress:  40.6% | Batch 15/37s\n",
      "✓\n",
      "Progress:  43.3% | Batch 16/37s\n",
      "✓\n",
      "Progress:  46.0% | Batch 17/37s\n",
      "✓\n",
      "Progress:  48.7% | Batch 18/37s\n",
      "✓\n",
      "Progress:  51.4% | Batch 19/37s\n",
      "✓\n",
      "Progress:  54.1% | Batch 20/37s\n",
      "✓\n",
      "Progress:  56.8% | Batch 21/37s\n",
      "✓\n",
      "Progress:  59.5% | Batch 22/37s\n",
      "✓\n",
      "Progress:  62.2% | Batch 23/37s\n",
      "✓\n",
      "Progress:  64.9% | Batch 24/37s\n",
      "✓\n",
      "Progress:  67.6% | Batch 25/37s\n",
      "✓\n",
      "Progress:  70.3% | Batch 26/37s\n",
      "✓\n",
      "Progress:  73.0% | Batch 27/37s\n",
      "✓\n",
      "Progress:  75.7% | Batch 28/37s\n",
      "✓\n",
      "Progress:  78.4% | Batch 29/37s\n",
      "✓\n",
      "Progress:  81.1% | Batch 30/37s\n",
      "✓\n",
      "Progress:  83.8% | Batch 31/37s\n",
      "✓\n",
      "Progress:  86.5% | Batch 32/37s\n",
      "✓\n",
      "Progress:  89.2% | Batch 33/37s\n",
      "✓\n",
      "Progress:  91.9% | Batch 34/37s\n",
      "✓\n",
      "Progress:  94.6% | Batch 35/37s\n",
      "✓\n",
      "Progress:  97.3% | Batch 36/37s\n",
      "✓\n",
      "Progress: 100.0% | Batch 37/37s\n"
     ]
    }
   ],
   "source": [
    "df = get_historical_data(kept_rics, start_date, end_date, fields = None)\n",
    "\n",
    "\n",
    "if isinstance(df, pd.Series):\n",
    "    df = df.to_frame(name=\"Price to Earning\")\n",
    "\n",
    "    \n",
    "df_final = df.reset_index()\n",
    "\n",
    "\n",
    "df_final.to_csv(BASE_DIR /\"lseg_Price-Earning_data_now_to_20260212_ADVfiltered.csv\", index = False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396c2cf6-fd5e-436b-b7eb-de4145a66b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = get_historical_data(\".SPX\", start_date, end_date, fields = None)\n",
    "\n",
    "df = ld.get_history(\n",
    "    universe=\".SPX\",\n",
    "    fields=\"TR.PriceClose\",\n",
    "    interval=\"daily\",\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    ")\n",
    "\n",
    "if isinstance(df, pd.Series):\n",
    "    df = df.to_frame(name=\"Close Price\")\n",
    "\n",
    "df_final.to_csv(BASE_DIR /\"lseg_historyprice_S&P500_now_to_20260212.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b56b2-0667-4f25-a8e1-3042d05facbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_usd_volume(df):\n",
    "    \"\"\"\n",
    "    Calculate USD trading volume for each (Date, RIC)\n",
    "\n",
    "    USD_Volume = Volume * Price Close * FX_Rate (if not USD)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain:\n",
    "        ['Volume', 'Price Close', 'Currency']\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        With added 'USD_Volume' column\n",
    "    \"\"\"\n",
    "    print(\"\\nCalculating USD volume...\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Sanity check\n",
    "    required_cols = {\"Volume\", \"Price Close\", \"Currency\"}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Base calculation (assume USD)\n",
    "    df[\"USD_Volume\"] = df[\"Volume\"] * df[\"Price Close\"]\n",
    "\n",
    "    # Identify non-USD rows\n",
    "    non_usd = df[\"Currency\"] != \"USD\"\n",
    "    non_usd_df = df.loc[df[\"Currency\"].ne(\"USD\")].copy()\n",
    "\n",
    "\n",
    "    if non_usd.any():\n",
    "        print(f\"⚠ {non_usd.sum()} rows are non-USD (FX rate = 1.0 placeholder)\")\n",
    "        # Placeholder FX rate\n",
    "        df.loc[non_usd, \"USD_Volume\"] *= 1.0\n",
    "\n",
    "    return df, non_usd_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1a61b-9074-4085-8726-a859e5c48500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adv(df, lookback_days=75, min_coverage=0.8):\n",
    "    print(f\"\\nCalculating {lookback_days}-day ADV for each stock...\")\n",
    "\n",
    "    adv_records = []\n",
    "\n",
    "    for ric, g in df.groupby(level=\"RIC\"):\n",
    "        g = g.sort_index(level=\"Date\")\n",
    "\n",
    "        recent = g.tail(lookback_days)\n",
    "        n_obs = recent[\"USD_Volume\"].notna().sum()\n",
    "\n",
    "        if n_obs >= lookback_days * min_coverage:\n",
    "            adv_records.append({\n",
    "                \"RIC\": ric,\n",
    "                \"ADV_USD\": recent[\"USD_Volume\"].mean(),\n",
    "                \"Days_Used\": n_obs,\n",
    "                \"Latest_Date\": recent.index.get_level_values(\"Date\")[-1]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"  Warning: Insufficient data for {ric} ({n_obs} days)\")\n",
    "\n",
    "    return pd.DataFrame(adv_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c9ab5-7632-47a7-8ceb-db4d041a3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_single_stock_limits(\n",
    "    adv_summary: pd.DataFrame,\n",
    "    threshold_usd: float = 5_000_000,\n",
    "    adv_col: str = \"ADV_USD\",\n",
    "    ric_col: str = \"RIC\",\n",
    "    pct_of_adv: float = 0.025,\n",
    "    max_usd_cap: float = 2_000_000,\n",
    "    limit_col: str = \"Daily_Limit_USD\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Step 1: Screen by ADV >= threshold_usd (e.g. 5M).\n",
    "    Step 2: For kept names, compute Daily_Limit_USD = min(pct_of_adv * ADV, max_usd_cap).\n",
    "\n",
    "    Returns:\n",
    "        filtered_adv: kept rows with Daily_Limit_USD added\n",
    "        excluded_adv: excluded rows (no daily limit computed)\n",
    "        kept_rics: list of kept RICs\n",
    "    \"\"\"\n",
    "    df = adv_summary.copy()\n",
    "\n",
    "    required = {adv_col, ric_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    df[adv_col] = pd.to_numeric(df[adv_col], errors=\"coerce\")\n",
    "\n",
    "    # Step 1: ADV screen\n",
    "    mask_keep = df[adv_col] >= threshold_usd\n",
    "    filtered_adv = df.loc[mask_keep].copy()\n",
    "    excluded_adv = df.loc[~mask_keep].copy()\n",
    "    kept_rics = filtered_adv[ric_col].dropna().tolist()\n",
    "\n",
    "    # Step 2: compute daily trading limit only for kept\n",
    "    filtered_adv[limit_col] = (filtered_adv[adv_col] * pct_of_adv).clip(upper=max_usd_cap)\n",
    "\n",
    "\n",
    "    return filtered_adv, excluded_adv, kept_rics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30622e82-91dc-406f-951b-5adaa9d8a542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
